146 LRU Cache
=======================
[Problem description](https://leetcode.com/problems/lru-cache/)

#### Difficulty
<span style="color:#FABC60">Medium</span>

#### Keywords
- [Cache](../categories/caching.md)
- [Linked list](../categories/linked_list.md)
  
#### Idea


#### Complexity
- Runtime: O(1)
- Space: O(N)
  
#### LC performance
- Runtime: 96 ms
- Memory usage: 21.8 MB

#### Code
##### Scratch
```python

class ListNode:
    """
    Doubly linked list node
    """
    
    def __init__(self, key, val):
        self.key = key
        self.val = val
        self.prev = self.next = None
    
class LRUCache:

    def __init__(self, capacity: int):
        # cache capacity
        self.capacity = capacity
        # map from keys to list nodes
        self.store = {}
        # head and tail of the doubly linked list
        self.head = self.tail = None

    def get(self, key: int) -> int:
        # return -1 if the key is not present in the cache
        if key not in self.store:
            return -1
        # find the node corresponding to the key
        n = self.store[key]
        # if the node is at the head of the linked list, no steps need to be 
        # taken but return the value immediately
        if n == self.head:
            return n.val
        # otherwise, pull the node out of the linked list first
        if n.prev:
            n.prev.next = n.next
        if n.next:
            n.next.prev = n.prev 
        # if the node is the tail of the list, update the tail with its previous 
        # node
        if n == self.tail:
            self.tail = n.prev
        # move the node to the front as the new head of the list
        n.prev, n.next = None, self.head
        self.head.prev = n
        self.head = n
        return n.val

    def put(self, key: int, value: int) -> None:
        # if the capacity is zero, nothing is to be put into the cache
        if self.capacity == 0:
            return 
        # if the key already exists in the cache
        if key in self.store:
            # update the value of the corresponding node
            self.store[key].val = value
            # move the node to the front of the doubly linked list
            self.get(key)
            return
        # otherwise, check if the cache is full first, since the new value is 
        # going to be put into the cache. If it is full, the node at the tail of 
        # the list will be evicted from the cache
        if len(self.store) == self.capacity:
            # find and evicted the tail node from the cache
            ev = self.tail
            del self.store[ev.key]
            # update the tail with the previous node of the evicted one
            self.tail = ev.prev 
            # if the new tail exists, point it to null as the next node to 
            # evict the old tail
            if self.tail:
                self.tail.next = None
            # otherwise, the evicted node is not only the tail but also the head 
            # of the list, so set the head to null as well
            else:
                self.head = None
        # create and put the new node into the cache
        n = ListNode(key, value)
        self.store[key] = n
        # if the head of the list is null, that means the cache is still empty, 
        # so the new node is the first one in the cache as both the head and 
        # tail of the list
        if not self.head:
            self.head = self.tail = n
        # otherwise, put the new node at the front of the list 
        else:
            n.next = self.head
            self.head.prev = n
            self.head = n
```
##### OrderedDict
```python
from collections import OrderedDict

class LRUCache:

    def __init__(self, capacity: int):
        self.capacity = capacity
        self.cache = OrderedDict()
        
    def get(self, key: int) -> int:
        cache = self.cache
        if key not in cache:
            return -1
        v = cache.pop(key)
        cache[key] = v
        return v

    def put(self, key: int, value: int) -> None:
        cache = self.cache
        if self.capacity == 0:
            return 
        if key in cache:
            cache.pop(key)
            cache[key] = value
            return
        if len(cache) + 1 > self.capacity:
            cache.popitem(last=False)
        cache[key] = value
        

# Your LRUCache object will be instantiated and called as such:
# obj = LRUCache(capacity)
# param_1 = obj.get(key)
# obj.put(key,value)
```